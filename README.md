# DSBA 6165 AI and Deep Learning Project (Spring 2025)
## ğŸ‘¥ Group 8 â€“ Personalized AI Writing Assistant

ğŸ” Project Overview
This project aims to develop a multi-model AI-powered writing assistant capable of generating both short-form (quotes, reflections) and long-form (SOPs, essays) texts in the unique writing style of the user. The solution leverages style conditioning, semantic alignment, and authorship verification to ensure stylistic authenticity and minimal hallucination.

ğŸ“ Project Structure
ğŸ“¦ AI-Writing-Assistant/
â”œâ”€â”€ ğŸ“‚ report/                   # Final report and supplementary documentation
â”‚   â”œâ”€â”€ 6165_Final_Report_Group_8.pdf
â”‚   â”œâ”€â”€ Final_model_documentation.docx
â”œâ”€â”€ ğŸ“‚ models/                   # Fine-tuned and baseline model scripts
â”‚   â”œâ”€â”€ gpt2_style_model.py
â”‚   â”œâ”€â”€ bart_longform_generator.py
â”‚   â”œâ”€â”€ t5_text_rewriter.py
â”‚   â””â”€â”€ authorship_classifier.py
â”œâ”€â”€ ğŸ“‚ data/                     # Preprocessed datasets (quotes, blogs, SOPs)
â”‚   â”œâ”€â”€ quotes_personal.csv
â”‚   â”œâ”€â”€ sop_samples.csv
â”‚   â””â”€â”€ author_labels.csv
â”œâ”€â”€ ğŸ“‚ notebooks/               # EDA, training logs, metric visualizations
â”‚   â”œâ”€â”€ shortform_generation.ipynb
â”‚   â””â”€â”€ authorship_eval.ipynb
â”œâ”€â”€ README.md                   # Project summary and usage guide

ğŸ”§ Technologies & Models Used
| Purpose                   | Model                               | Notes                                       |
| ------------------------- | ----------------------------------- | ------------------------------------------- |
| Short-form generation     | GPT-2 (LoRA fine-tuned)             | Controlled via metadata & few-shot examples |
| Long-form generation      | BART, Meta LLaMA, Mistral           | Chosen based on fluency and coherence       |
| Style rewriting           | T5 + TextSETTR                      | For tone-specific quote transformation      |
| Evaluation                | BERTScore, SpaCy, Custom Classifier | Ensures semantic and stylistic fidelity     |
| Authorship Classification | Logistic Regression                 | Predicts if text matches user's style       |

ğŸ¯ Key Features
Style Conditioning: Metadata tags like tone, theme, and formality help guide generation.

Few-shot Prompting: Stabilizes model behavior using examples.

Style Verification: Ensures generated content matches the author's signature style.

Custom Post-Processing: Removes hallucinations and ensures emotional coherence.

ğŸ“Š Evaluation Highlights
BERTScore (F1): 0.84 on short-form quotes

Classifier Accuracy: 88.5% on authorship validation

Human Evaluation: 9/10 testers agreed generated content matched the authorâ€™s style

ğŸ§  Future Scope
Add reinforcement learning with human feedback (RLHF) for emotional alignment.

Expand authorship classifier to support multi-author confusion matrix.

Explore integration with web UIs like Streamlit or Gradio for public demo.

ğŸ™Œ Acknowledgments
Special thanks to Prof. Fox for project guidance.

Base models: HuggingFace Transformers, TinyLLaMA, and TextSETTR.
